{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPwurXLRzHIO0Fdw3GOFOJp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ankitsharma38/Machine_Learning_LABS/blob/main/Practical_11_14.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Practical 11: Explore the association rule mining techniques using sample data.**"
      ],
      "metadata": {
        "id": "bWFJRXmzgjOd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 1 install necessary library\n",
        "!pip install mlxtend pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JyZX8H15hDqA",
        "outputId": "1bdb8899-c390-4fdc-d5d0-e5f7c4a95408"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mlxtend in /usr/local/lib/python3.11/dist-packages (0.23.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scipy>=1.2.1 in /usr/local/lib/python3.11/dist-packages (from mlxtend) (1.14.1)\n",
            "Requirement already satisfied: numpy>=1.16.2 in /usr/local/lib/python3.11/dist-packages (from mlxtend) (2.0.2)\n",
            "Requirement already satisfied: scikit-learn>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from mlxtend) (1.6.1)\n",
            "Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from mlxtend) (3.10.0)\n",
            "Requirement already satisfied: joblib>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from mlxtend) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (3.2.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.3.1->mlxtend) (3.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import pandas as pd\n",
        "from mlxtend.frequent_patterns import apriori,association_rules\n",
        "\n",
        "data = {\n",
        "    'Milk':[1, 1, 0, 1, 0],\n",
        "    'Bread':[1, 0, 1, 1, 0],\n",
        "    'Eggs':[0, 1, 1, 0, 1],\n",
        "    'Butter':[1, 0, 0, 1, 0],\n",
        "}\n",
        "\n",
        "df= pd.DataFrame(data)\n",
        "df = df.astype(bool)\n",
        "print(\"Transaction Dataset (Converted to Boolean)\")\n",
        "print(df)\n",
        "frequent_itemsets = apriori(df,min_support=0.4,use_colnames=True)\n",
        "print(\"\\nFrequent Itemsets:\")\n",
        "print(frequent_itemsets)\n",
        "\n",
        "rules = association_rules(frequent_itemsets,metric='confidence',min_threshold=0.4)\n",
        "print(\"\\nAssociation Rules:\")\n",
        "print(rules[['antecedents','consequents','support','confidence','lift']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tFqxlUrhjyW",
        "outputId": "0050042a-a7fc-4733-bba1-eeb0243a1c3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transaction Dataset (Converted to Boolean)\n",
            "    Milk  Bread   Eggs  Butter\n",
            "0   True   True  False    True\n",
            "1   True  False   True   False\n",
            "2  False   True   True   False\n",
            "3   True   True  False    True\n",
            "4  False  False   True   False\n",
            "\n",
            "Frequent Itemsets:\n",
            "   support               itemsets\n",
            "0      0.6                 (Milk)\n",
            "1      0.6                (Bread)\n",
            "2      0.6                 (Eggs)\n",
            "3      0.4               (Butter)\n",
            "4      0.4          (Milk, Bread)\n",
            "5      0.4         (Milk, Butter)\n",
            "6      0.4        (Bread, Butter)\n",
            "7      0.4  (Milk, Bread, Butter)\n",
            "\n",
            "Association Rules:\n",
            "        antecedents      consequents  support  confidence      lift\n",
            "0            (Milk)          (Bread)      0.4    0.666667  1.111111\n",
            "1           (Bread)           (Milk)      0.4    0.666667  1.111111\n",
            "2            (Milk)         (Butter)      0.4    0.666667  1.666667\n",
            "3          (Butter)           (Milk)      0.4    1.000000  1.666667\n",
            "4           (Bread)         (Butter)      0.4    0.666667  1.666667\n",
            "5          (Butter)          (Bread)      0.4    1.000000  1.666667\n",
            "6     (Milk, Bread)         (Butter)      0.4    1.000000  2.500000\n",
            "7    (Milk, Butter)          (Bread)      0.4    1.000000  1.666667\n",
            "8   (Bread, Butter)           (Milk)      0.4    1.000000  1.666667\n",
            "9            (Milk)  (Bread, Butter)      0.4    0.666667  1.666667\n",
            "10          (Bread)   (Milk, Butter)      0.4    0.666667  1.666667\n",
            "11         (Butter)    (Milk, Bread)      0.4    1.000000  2.500000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Practical 12: Implement ANN using sample data.**"
      ],
      "metadata": {
        "id": "o8E5T8u6nGme"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Implement ANN using sample data using mnist dataset tensorflow ,normallize it,reshape it to 28*28*1 and then select sqquential model\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Load the MNIST dataset\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Normalize the pixel values\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Reshape the data\n",
        "x_train = x_train.reshape(-1, 28, 28, 1)\n",
        "x_test = x_test.reshape(-1, 28, 28, 1)\n",
        "\n",
        "\n",
        "# Define the ANN model\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(28, 28, 1)),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=10)\n",
        "\n",
        "# Evaluate the model\n",
        "model.evaluate(x_test,  y_test, verbose=2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcLSz_ZcnKmP",
        "outputId": "b90cd7b5-2595-470a-9814-06038137433b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.8651 - loss: 0.4710\n",
            "Epoch 2/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9554 - loss: 0.1512\n",
            "Epoch 3/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9654 - loss: 0.1105\n",
            "Epoch 4/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9722 - loss: 0.0901\n",
            "Epoch 5/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9775 - loss: 0.0737\n",
            "Epoch 6/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9810 - loss: 0.0617\n",
            "Epoch 7/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9812 - loss: 0.0586\n",
            "Epoch 8/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9826 - loss: 0.0519\n",
            "Epoch 9/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9853 - loss: 0.0441\n",
            "Epoch 10/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9863 - loss: 0.0418\n",
            "313/313 - 1s - 4ms/step - accuracy: 0.9804 - loss: 0.0752\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.07521696388721466, 0.980400025844574]"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Practical 13:- Exploring activation function in ANN.**"
      ],
      "metadata": {
        "id": "LYH5y3u-id1b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import models, layers\n",
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "(X_train,y_train) , (X_test,y_test) = mnist.load_data()\n",
        "\n",
        "# Normalize the pixel values\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "\n",
        "#reshape\n",
        "X_train = X_train.reshape(-1, 28*28)\n",
        "X_test = X_test.reshape(-1, 28*28)\n",
        "\n",
        "\n",
        "#function to create model with different activation function\n",
        "def create_model(activation_function):\n",
        "  model = models.Sequential()\n",
        "  model.add(layers.Dense(128, activation=activation_function, input_shape=(28*28,)))\n",
        "  model.add(layers.Dense(10, activation='softmax'))\n",
        "  model.compile(optimizer='adam',\n",
        "                loss='sparse_categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "# Test different activation functions\n",
        "activation_functions = ['relu', 'sigmoid', 'softmax', 'tanh']\n",
        "\n",
        "result={}\n",
        "\n",
        "for i in activation_functions:\n",
        "  print(f\"Training model with {i} activation function\")\n",
        "  model = create_model(i)\n",
        "  model.fit(X_train, y_train, epochs=5, validation_data=(X_test, y_test))\n",
        "  test_Loss, test_acc=model.evaluate(X_test,y_test)\n",
        "  print(f\"Test accuracy: {test_acc}\")\n",
        "  result[i]=test_acc\n",
        "  print(f\"Test Accuracy: {test_acc}\")\n",
        "  print(f\"Test Loss: {test_Loss}\")\n",
        "\n",
        "print(\"\\n Results:\")\n",
        "for i,j in result.items():\n",
        "  print(f\"Activation ={i}: with test accuracy= {j}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yyMa0GUbi1wq",
        "outputId": "78ec5e3d-21f4-48d5-88bf-54dd93538480"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Training model with relu activation function\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - accuracy: 0.8792 - loss: 0.4304 - val_accuracy: 0.9616 - val_loss: 0.1304\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9634 - loss: 0.1219 - val_accuracy: 0.9712 - val_loss: 0.0951\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9755 - loss: 0.0800 - val_accuracy: 0.9733 - val_loss: 0.0825\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9825 - loss: 0.0559 - val_accuracy: 0.9747 - val_loss: 0.0809\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9872 - loss: 0.0420 - val_accuracy: 0.9783 - val_loss: 0.0693\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9748 - loss: 0.0828\n",
            "Test accuracy: 0.9782999753952026\n",
            "Test Accuracy: 0.9782999753952026\n",
            "Test Loss: 0.06925949454307556\n",
            "Training model with sigmoid activation function\n",
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8340 - loss: 0.6739 - val_accuracy: 0.9339 - val_loss: 0.2256\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9381 - loss: 0.2166 - val_accuracy: 0.9516 - val_loss: 0.1641\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9566 - loss: 0.1514 - val_accuracy: 0.9604 - val_loss: 0.1342\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9650 - loss: 0.1178 - val_accuracy: 0.9660 - val_loss: 0.1103\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.9740 - loss: 0.0921 - val_accuracy: 0.9699 - val_loss: 0.0980\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9651 - loss: 0.1097\n",
            "Test accuracy: 0.9699000120162964\n",
            "Test Accuracy: 0.9699000120162964\n",
            "Test Loss: 0.097958505153656\n",
            "Training model with softmax activation function\n",
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.7126 - loss: 1.6397 - val_accuracy: 0.7909 - val_loss: 0.7395\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.7916 - loss: 0.6775 - val_accuracy: 0.7861 - val_loss: 0.5524\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.8068 - loss: 0.5355 - val_accuracy: 0.8217 - val_loss: 0.4993\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8503 - loss: 0.4706 - val_accuracy: 0.8716 - val_loss: 0.4383\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8855 - loss: 0.4114 - val_accuracy: 0.8903 - val_loss: 0.3946\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8762 - loss: 0.4255\n",
            "Test accuracy: 0.8902999758720398\n",
            "Test Accuracy: 0.8902999758720398\n",
            "Test Loss: 0.39464429020881653\n",
            "Training model with tanh activation function\n",
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8738 - loss: 0.4342 - val_accuracy: 0.9480 - val_loss: 0.1706\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9561 - loss: 0.1488 - val_accuracy: 0.9633 - val_loss: 0.1207\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9712 - loss: 0.0986 - val_accuracy: 0.9707 - val_loss: 0.0963\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.9802 - loss: 0.0688 - val_accuracy: 0.9735 - val_loss: 0.0865\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9857 - loss: 0.0509 - val_accuracy: 0.9748 - val_loss: 0.0771\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9719 - loss: 0.0863\n",
            "Test accuracy: 0.9747999906539917\n",
            "Test Accuracy: 0.9747999906539917\n",
            "Test Loss: 0.07713273912668228\n",
            "\n",
            " Results:\n",
            "Activation =relu: with test accuracy= 0.9782999753952026\n",
            "Activation =sigmoid: with test accuracy= 0.9699000120162964\n",
            "Activation =softmax: with test accuracy= 0.8902999758720398\n",
            "Activation =tanh: with test accuracy= 0.9747999906539917\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Practical 14: Implementation of Transformer Neural Network model.**"
      ],
      "metadata": {
        "id": "7zinP0EtrTY6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class simpleNN:\n",
        "  def __init__(self):  # Fixed constructor name\n",
        "    self.weights1 = np.random.rand(2, 3)\n",
        "    self.weights2 = np.random.rand(3, 1)\n",
        "\n",
        "  def forward(self, X):\n",
        "    self.z1 = np.dot(X, self.weights1)\n",
        "    self.a1 = self.sigmoid(self.z1)\n",
        "    self.z2 = np.dot(self.a1, self.weights2)\n",
        "    self.output = self.sigmoid(self.z2)\n",
        "    return self.output\n",
        "\n",
        "  def sigmoid(self, s):\n",
        "    return 1 / (1 + np.exp(-s))\n",
        "\n",
        "  def mse_loss(self, y_pred, y_true):\n",
        "    return ((y_pred - y_true) ** 2).mean()\n",
        "\n",
        "  def train(self, X, y, learning_rate=0.01, epochs=100):  # Fixed typo in parameter name\n",
        "    for i in range(epochs):\n",
        "      output = self.forward(X)\n",
        "      loss = self.mse_loss(output, y)\n",
        "\n",
        "      d_output = (output - y) * output * (1 - output)\n",
        "      d_weights2 = np.dot(self.a1.T, d_output)\n",
        "      d_hidden = np.dot(d_output, self.weights2.T) * self.a1 * (1 - self.a1)\n",
        "      d_weights1 = np.dot(X.T, d_hidden)\n",
        "\n",
        "      self.weights1 -= learning_rate * d_weights1\n",
        "      self.weights2 -= learning_rate * d_weights2\n",
        "\n",
        "      if i % 10 == 0:\n",
        "        print(f\"Epoch {i} , Loss {loss}\")\n",
        "\n",
        "# XOR task\n",
        "X_task1 = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "y_task1 = np.array([[0], [1], [1], [0]])\n",
        "\n",
        "nn = simpleNN()\n",
        "print(\"Training on task1 (XOR): \")\n",
        "nn.train(X_task1, y_task1, epochs=100)\n",
        "print(\"\\nTesting on task1 (XOR): \")\n",
        "print(nn.forward(X_task1))\n",
        "\n",
        "# AND task\n",
        "X_task2 = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "y_task2 = np.array([[0], [0], [0], [1]])\n",
        "print(\"\\nTraining on task2 (AND): \")\n",
        "nn.train(X_task2, y_task2, epochs=100)\n",
        "print(\"\\nTesting on task2 (AND): \")\n",
        "print(nn.forward(X_task2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UFd6XOXrw9i",
        "outputId": "9a956268-1d33-4a4f-a2c4-a00e29942651"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on task1 (XOR): \n",
            "Epoch 0 , Loss 0.30780998305605783\n",
            "Epoch 10 , Loss 0.3059661782869993\n",
            "Epoch 20 , Loss 0.3041480343962655\n",
            "Epoch 30 , Loss 0.30235719375553854\n",
            "Epoch 40 , Loss 0.30059521588080124\n",
            "Epoch 50 , Loss 0.2988635702218483\n",
            "Epoch 60 , Loss 0.2971636297053245\n",
            "Epoch 70 , Loss 0.2954966650967473\n",
            "Epoch 80 , Loss 0.2938638402336122\n",
            "Epoch 90 , Loss 0.2922662081675109\n",
            "\n",
            "Testing on task1 (XOR): \n",
            "[[0.67884027]\n",
            " [0.70631924]\n",
            " [0.69859793]\n",
            " [0.72450198]]\n",
            "\n",
            "Training on task2 (AND): \n",
            "Epoch 0 , Loss 0.3809123016562683\n",
            "Epoch 10 , Loss 0.37402136885059406\n",
            "Epoch 20 , Loss 0.3672368077588823\n",
            "Epoch 30 , Loss 0.36057402731436555\n",
            "Epoch 40 , Loss 0.3540473577563538\n",
            "Epoch 50 , Loss 0.34766989308801965\n",
            "Epoch 60 , Loss 0.3414533630303835\n",
            "Epoch 70 , Loss 0.33540803709990386\n",
            "Epoch 80 , Loss 0.3295426620353382\n",
            "Epoch 90 , Loss 0.32386443241831775\n",
            "\n",
            "Testing on task2 (AND): \n",
            "[[0.60906865]\n",
            " [0.62228229]\n",
            " [0.61475632]\n",
            " [0.6293374 ]]\n"
          ]
        }
      ]
    }
  ]
}